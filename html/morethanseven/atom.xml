<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Morethanseven]]></title>
  <link href="http://www.morethanseven.net/atom.xml" rel="self"/>
  <link href="http://www.morethanseven.net/"/>
  <updated>2013-02-17T17:15:21+00:00</updated>
  <id>http://www.morethanseven.net/</id>
  <author>
    <name><![CDATA[Gareth Rushgrove]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Going fast in government]]></title>
    <link href="http://www.morethanseven.net/2013/02/17/going-fast-in-government/"/>
    <updated>2013-02-17T17:08:00+00:00</updated>
    <id>http://www.morethanseven.net/2013/02/17/going-fast-in-government</id>
    <content type="html"><![CDATA[<p>About a month ago I had the good fortune of speaking at the <a href="http://www.meetup.com/London-Web-Performance-Group/">London Web Performance</a> meetup. This was one of the first talks I&#8217;ve done about our work at The Government Digital Service since the luanch of <span class="caps">GOV</span>.UK back in October. The topic was all about moving quickly in a large organisation (The UK Civil Service is about 450,000 people so I think it counts) and featured just a hand full of technical and organisational tricks we used.</p>
<script async class="speakerdeck-embed" data-id="bc48ed2042c20130b322123138156909" data-ratio="1.33333333333333" src="http://www.morethanseven.net//speakerdeck.com/assets/embed.js"></script>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Django and Rails presentation from QCon]]></title>
    <link href="http://www.morethanseven.net/2013/01/13/django-and-rails-presentation-from-qcon/"/>
    <updated>2013-01-13T16:31:00+00:00</updated>
    <id>http://www.morethanseven.net/2013/01/13/django-and-rails-presentation-from-qcon</id>
    <content type="html"><![CDATA[<p>I had great fun back in November at the <a href="http://qconsf.com/">QCon</a> conference in San Francisco. As well as currating one of the tracks and catching up with people in the area I managed to give the following talk.</p>
<script async class="speakerdeck-embed" data-id="7e1dd5a03efc0130083b123139173def" data-ratio="1.33333333333333" src="http://www.morethanseven.net//speakerdeck.com/assets/embed.js"></script><p>In hindsight it might have been a bit odd to try and cover both Rails and Django examples in the one presentation but it was quite good fun putting together code examples using both of them at the same time. As well as a large set of tips, tricks and tools I settled on a few things that I think any web (or other) framework should support out of the box.</p>
<ul>
	<li>A debug toolbar</li>
	<li>Transparent caching support</li>
	<li>Hooks for instrumentation</li>
	<li>Configurable logging</li>
</ul>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[my personal package repository]]></title>
    <link href="http://www.morethanseven.net/2012/12/30/my-personal-package-repository/"/>
    <updated>2012-12-30T16:52:00+00:00</updated>
    <id>http://www.morethanseven.net/2012/12/30/my-personal-package-repository</id>
    <content type="html"><![CDATA[<p>I&#8217;m a <a href="http://www.morethanseven.net/2011/01/16/Why-developers-should-care-about-system-packages/">big fan of system packages for lots of reasons</a> and have often ended up rolling my own debian package repository at work, or working with others that have done so. Recently I finally got round to setting up a personal package repo, at <a href="http://packages.garethrushgrove.com">packages.garethrushgrove.com</a>. More interesting than the repo is probably the tool chain I used, oh and the rather nice bootstrap based styling.</p>
<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRjh1wIM" alt="nice looking package repository"/></p>
<p>The source code for everything is <a href="https://github.com/garethr/packages">on GitHub</a> although not much documentation exists yet. In the middle are a few shell scripts that generate the repo. Around them is a Vagrant box (which makes it easier to build packages for different achitectures or distros) and some Rake commands</p>
<pre><code>bundle exec rake -T
rake recipes:build[recipe]  # Build a package from one of the available recipes
rake recipes:list           # List available recipes
rake repo:build             # Build the repository</code></pre>
<p>The recipes commands allow for building new packages based on scripts. A few examples are included which use fpm, but you could use anything. The repo:build command triggers the debian repository to be rebuilt.</p>
<p>The vagrant configuration shares various folders between and guest and host which also opens up a few useful features. One is I can just drop any old debian package into the debs folder and run the repo:build command and it will be in my repository. The other useful capability is that the resulting repo is shared back to the host, which means I can then check it into Git and in my case push it up to Heroku.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On the forge]]></title>
    <link href="http://www.morethanseven.net/2012/12/03/on-the-forge/"/>
    <updated>2012-12-03T08:18:00+00:00</updated>
    <id>http://www.morethanseven.net/2012/12/03/on-the-forge</id>
    <content type="html"><![CDATA[<p>I&#8217;ve been spending a bit of time recently pushing a few Puppet modules to the <a href="http://forge.puppetlabs.com">Forge</a>. This is Puppetlabs attempt to make a central repository of reusable puppet modules. I started doing it as a bit of an experiment, to find out what I liked and what worked and I decided to writeup a few opinions.</p>
<p>So far I&#8217;ve shipped the following modules:</p>
<ul>
	<li><a href="http://forge.puppetlabs.com/garethr/riemann">Riemann</a></li>
	<li><a href="http://forge.puppetlabs.com/garethr/graphite">Graphite</a></li>
	<li><a href="http://forge.puppetlabs.com/garethr/logstash">Logstash</a></li>
	<li><a href="http://forge.puppetlabs.com/garethr/freight">Freight</a></li>
</ul>
<p>Quite a few of these started as forks of other modules but have evolved quite a bit towards being more reusable.</p>
<p>I&#8217;ve also started sending pull requests for modules that basically do what I want but don&#8217;t always play well with others.</p>
<ul>
	<li><a href="https://github.com/thomasvandoren/puppet-redis/pull/10">Redis</a></li>
</ul>
<h2>Improved tools</h2>
<p>It turns out the experience is mainly a pleasurable one, partly down to the much improved tooling around Puppet. Specifically I&#8217;m making extensive use of:</p>
<ul>
	<li><a href="http://rspec-puppet.com/">Rspec Puppet</a> &#8211; for writing tests for module behavious</li>
	<li><a href="https://github.com/rodjek/librarian-puppet">Librarian Puppet</a> &#8211; dependency management for modules</li>
	<li><a href="https://github.com/puppetlabs/puppetlabs_spec_helper">Puppet spec helper</a> &#8211; conventions and helpers for testing modules</li>
	<li><a href="https://travis-ci.org/">Travis CI</a> &#8211; easy continuous integration for module code</li>
	<li><a href="http://vagrantup.com/">Vagrant</a> &#8211; manage virtual machines, useful for smoke testing on different distributions</li>
</ul>
<p>Lots of those tools make testing Puppet modules both easier and useful. Here&#8217;s an example of one of the above modules being tested. Note that it&#8217;s run across Ruby 1.8.7, 1.9.2 and 1.9.3 and Puppet versions 2.7.17, 2.7.18 and 3.0.1 for a total of 9 builds. Handily the Redis module mentioned also had a test suite. The pull request includes changes to that, and Travis <a href="https://travis-ci.org/thomasvandoren/puppet-redis/builds/3462513">automatically tested the pull request</a> for the modules author.</p>
<h2>Antipatterns</h2>
<p>Using modules from the Forge really forces you to think about reusability. The pull request mentioned above for the Redis module for instance replaced an explicit mention of the build-essential package with the &#8220;puppetlabs/gcc&#8221;: class from the Forge. This makes the module less self contained, but without that change the module is incompatible with any other module that also uses that common package. I also went back and replaced explicit references to wget and build-essential in my Riemann module.</p>
<p>As a rule of thumb. For a specific module only include resources that are unique to the software the module manages. Anything else should be in another module with a dependency in the Modulefile.</p>
<p>This can feel a little much when you&#8217;re replacing a simple Package resource with a whole new module but it has two advantages I care about. As well as the ability to use the module with other third party modules more easily it also makes it more likely that the module will work cross platform.</p>
<h2>What&#8217;s missing?</h2>
<p>I&#8217;d like to see a few things improved when it comes to the Forge.</p>
<ul>
	<li>I&#8217;d like to be able to publish a new version of a module without having to use the web interface. The current workflow involves running a build command, then uploading the generated artifact via a web form after logging in.</li>
	<li>I&#8217;d like to see best practice module development guides front and centre on the Forge. Lots of modules won&#8217;t work with other modules and I think that&#8217;s fixable.</li>
	<li>Integration with puppet-lint would be nice, giving some indication of whether the authors care about the Puppet styleguide.</li>
	<li><del>A command line search interface would be useful</del>. And <a href="http://docs.puppetlabs.com/man/module.html">turns out to exist</a>. Thanks <a href="http://twitter.com/a1cy">@a1cy</a> for the heads up.</li>
	<li>The Forge tracks number of downloads, but as a publisher I don&#8217;t know how often my modules have been downloaded.</li>
	<li>And finally I&#8217;d like to see more people using it.</li>
</ul>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Shipping]]></title>
    <link href="http://www.morethanseven.net/2012/10/21/shipping/"/>
    <updated>2012-10-21T21:50:00+01:00</updated>
    <id>http://www.morethanseven.net/2012/10/21/shipping</id>
    <content type="html"><![CDATA[<p>Last week we shipped <a href="https://www.gov.uk"><span class="caps">GOV</span>.UK</a>. Over the last year we&#8217;ve built a team to build a website. Now we&#8217;re busy building a culture too. I&#8217;ve got so much that needs writing up about everything we&#8217;ve been up to. Hopefully I&#8217;ll make a start in the next week or so.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Tale Of A Grok Pattern]]></title>
    <link href="http://www.morethanseven.net/2012/08/19/Tale-of-a-grok-pattern/"/>
    <updated>2012-08-19T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2012/08/19/Tale-of-a-grok-pattern</id>
    <content type="html"><![CDATA[<p>I&#8217;m all of a sudden adding lots more code to GitHub. Here&#8217;s the latest project, <a href="https://github.com/garethr/logstash-patterns">grok patterns for logstash</a>. At the moment this repo only contains one new pattern but I&#8217;m hoping to add more, and maybe even for others to add more too.</p>
<p>First, a bit of background. <a href="http://logstash.net/">Logstash</a> is the excellent, open source, log agregation and processing framework. It takes inputs from various configurable places, processes them with filters and then outputs the results. So maybe you&#8217;ll take inputs from various application log files and output then into an elastic search index for easy searching, or output the same inputs to graphite and statsd to get graphs of rates. One of the host powerful filters in logstash is the <a href="http://logstash.net/docs/1.0.17/filters/grok">grok filter</a>. It takes a grok pattern and parses out information contained in the text into fields that can be more easily used by outputs. This post serves hopefully as both an explanation of why and an example of how you might do that.</p>
<h2>The problem</h2>
<p>Rails logs are horrible, that is until you install the excellent <a href="https://github.com/roidrage/lograge">lograge</a> output formatter. That gives you lines like:</p>
<pre>GET /jobs/833552.json format=json action=jobs#show status=200 duration=58.33 view=40.43 db=15.26</pre>
<p>This contains loads of useful information that&#8217;s easily parsable by a developer. We have the <span class="caps">HTTP</span> status code, the rails controller and information about response time too. A grok filter lets us teach logstash about that information too. The working grok filter for filtering this line looks like this:</p>
<h2>The solution</h2>
<pre>LOGRAGE %{WORD:method}%{SPACE}%{DATA}%{SPACE}action=%{WORD:controller}#%{WORD:action}%{SPACE}status=%{INT:status}%{SPACE}duration=%{NUMBER:duration}%{SPACE}view=%{NUMBER:view}(%{SPACE}db=%{NUMBER:db})?%{GREEDYDATA}</pre>
<p>That was worked out pretty much with a bit of trial and error and use of the logstash java binary, using stdin and stdout inputs and outputs. It works but getting their wasn&#8217;t that much funand proving it works outside a running logstash setup was tricky. Enter rspec and the grok implementation in pure Ruby. The project above contains an Rspec matcher for use when testing grok filters for logstash. I&#8217;ll probably extract that into a gem at some point but you&#8217;ll get the idea. Now we can write tests like these:</p>
<pre>the lograge grok pattern
  with a standard lograge log line
    should have the correct http method value
    should have the correct value for the request duration
    should have the correct value for the request view time
    should have the correct controller and action
    should have the correct value for db time
  without the db time
    should have the correct value for the request view time
  with a post request
    should have the correct http method value

Finished in 0.01472 seconds
7 examples, 0 failures
</pre>
<p>The <a href="https://github.com/garethr/logstash-patterns/blob/master/spec/lograge_spec.rb">tests themselves</a> are just basic Rspec with most of the work done in the <a href="https://github.com/garethr/logstash-patterns/blob/master/spec/spec_helper.rb">custom matcher</a>. This not only means I can be a bit more confident that my grok pattern works, it also provides a much nicer framework for writing more patterns for other log formats. Parsing rules like this are one area where test driven development is a huge boon in my experience. And with tests comes continuous integration, in this case via <a href="http://travis-ci.org/#!/garethr/logstash-patterns">Travis</a>.</p>
<p>I&#8217;ll hopefully find myself writing more patterns and tests for them, and if anyone wants to send pull requests and to start collecting working grok patterns together so much the better.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Riemann Puppet Module]]></title>
    <link href="http://www.morethanseven.net/2012/08/11/Riemann-puppet-module/"/>
    <updated>2012-08-11T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2012/08/11/Riemann-puppet-module</id>
    <content type="html"><![CDATA[<p>Thanks to an <a href="https://twitter.com/bitprophet/status/233626675307479040">errant tweet</a> I started playing with <a href="http://aphyr.github.com/riemann/">Riemann</a> again. It ticks lots of boxes for me, from the clojure to configuration as code and the overloadable dashboard application. What started as using Puppet and Vagrant to investigate Riemann turned into a full blown tool and module writing exercise, resulting in two related projects on GitHub.</p>
<ul>
	<li><a href="https://github.com/garethr/garethr-riemann/">garethr-riemann</a> is a Puppet module for installing and configuring Riemann. It allows for easily specifying your own server configuration and dashboard views.</li>
	<li><a href="https://github.com/garethr/riemann-vagrant">riemann-vagrant</a> is a Vagrantfile and other code which uses above puppet module to setup a local testing environment.</li>
</ul>
<p>I like this combination, a separate Puppet module along with a vagrant powered test bed. I&#8217;ve written a reasonable rspec based test suite to check the module but it&#8217;s always easier to be able to run <em>vagrant provision</em> as well to check everything is working. This also turned out to be the perfect opportunity to use <a href="https://github.com/rodjek/librarian-puppet">Librarian-Puppet</a> to manage the dependencies and eventually to ship the module to the <a href="https://forge.puppetlabs.com/garethr/riemann">Puppet Forge</a>.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Vagrantbox.es Story]]></title>
    <link href="http://www.morethanseven.net/2012/07/01/The-vagrantbox.es-story/"/>
    <updated>2012-07-01T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2012/07/01/The-vagrantbox.es-story</id>
    <content type="html"><![CDATA[<p>A few weeks ago now <a href="http://www.vagrantbox.es/">Vagrantbox.es</a> (a website I maintain for third party hosted <a href="http://vagrantup.com/">Vagrant</a> base boxes) dissapeared from the internet for a few days. This was completely my fault, the (lovely) hosting people <a href="https://www.ep.io/">ep.io</a> had unfortunately closed down the service they had in beta and I&#8217;d been so busy that I hadn&#8217;t had chance to move it elsewhere.</p>
<p>The original version of the site (I had the code and good backups of the data) was a pretty simple Django application, but I&#8217;d used it to experiment (read over-engineer) with various bits of tech including Varnish, Solr, some <span class="caps">ORM</span> caching and lots more. This had been great, but it made it less portable. I had everything described in Puppet, but with virtually no spare time I decided to go a different route.</p>
<p>I threw a flat version of the site up on <a href="https://github.com/garethr/vagrantboxes-heroku">GitHub</a>, served it using Nginx on <a href="http://www.heroku.com/">Heroku</a> and added a quick <em>Fork me on GitHub</em> badge to the top. Suggest a box moved from being a web form to a pull request. It&#8217;s fair to say I did this pretty quickly and made a good few typos on the way. But within a couple of weeks I&#8217;ve had 8 pull requests either fixing my bugs, removing dead boxes and adding new ones.</p>
<p>What I&#8217;m going to take from this is, if you&#8217;re building a community project that&#8217;s aimed at developers, then throw the content on GitHub. In my case I have the entire site on there too but I think that&#8217;s secondary. Pull requests are much better than any content management system or workflow you&#8217;re likely to build, and even more importantly the time to implement something drops hugely.</p>
<p>With all the spare time I don&#8217;t have I&#8217;ll be thinking about a content management model using GitHub for content, pull requests for workflow and post commit hooks for loading that content into a site or service somewhere.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Static Sites With Nginx On Heroku]]></title>
    <link href="http://www.morethanseven.net/2012/06/05/Static-sites-with-nginx-on-heroku/"/>
    <updated>2012-06-05T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2012/06/05/Static-sites-with-nginx-on-heroku</id>
    <content type="html"><![CDATA[<p>I have a few static sites on Heroku but in one case in particular I already had quite an involved nginx configuration &#8211; mainly 410s for some previous content and a series of redirects from older versions of the site. The common way of having static sites on Heroku appears to be to use a simple Rack middleware, but that would have meant reimplementing lots of boring redirect logic.</p>
<p>Heroku <a href="https://devcenter.heroku.com/articles/buildpacks">buildpacks</a> are great. The newer cedar stack is no longer tied to a particular language or framework, instead all of the discovery and knowledge about particular software is put into a buildpack. As well as the Heroku provided list it&#8217;s possible to write you&#8217;re own. Or in this case use one someone has <a href="https://github.com/essh/heroku-buildpack-nginx">created earlier</a>.</p>
<p>I&#8217;ve just moved <a href="http://www.vagrantbox.es/">Vagrantbox.es</a> over to Heroku due to the closure of a previous service. In doing that, instead of the simple database backed app, I&#8217;ve simply thrown all the content onto <a href="https://github.com/garethr/vagrantboxes-heroku">GitHub</a>. This means anyone can fork the content and send pull requests. Hopefully this should mean I pay a bit more attention to suggestions and new boxes.</p>
<p>The repository is a nice simple example of using the mentioned Heroku Nginx buildpack too. You just run the following command to create a new Heroku application.</p>
<pre>heroku create --stack cedar --buildpack http://github.com/essh/heroku-buildpack-nginx.git</pre>
<p>And then in typical Heroku fashion use a git remote to deploy changes and updates. The repository is split into a <em>www</em> folder with the site content and a <em>conf</em> folder with the nginx configuration. The only clever parts involve the use of an <span class="caps">ERB</span> template for the nginx configuration file so we can pickup the correct port. We also use 1 worker process and don&#8217;t automatically daemonize the process &#8211; Heroku deals with this itself.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Self Contained Jruby Web Applications]]></title>
    <link href="http://www.morethanseven.net/2012/04/06/Self-contained-jruby-web-applications/"/>
    <updated>2012-04-06T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2012/04/06/Self-contained-jruby-web-applications</id>
    <content type="html"><![CDATA[<p>Several things seemed to come together at once to make me want to hack on this particular project. In no particular order:</p>
<p>The <a href="http://www.thoughtworks.com/articles/technology-radar-march-2012">Thoughtworks Technology Radar</a> said the following:</p>
<blockquote>
<p>Embedding a servlet container, such as Jetty, inside a Java application has many advantages over running the application inside a container. Testing is relatively painless because of the simple startup, and the development environment is closer to production. Nasty surprises like mismatched versions of libraries or drivers are eliminated by not sharing across multiple applications. While you will have to manage and monitor multiple Java Virtual Machines in production using this model, we feel the advantages offered by the simplicity and isolation are significant.</p>
</blockquote>
<p>I&#8217;ve been getting more interested in JRuby anyway, partly because we&#8217;re finding ourselves using both Ruby and Scala at work, and maintaining a single target platform makes sense to me. Throw in the potential for interop between those languages and it&#8217;s certainly worth investigating.</p>
<p><a href="http://www.playframework.org/">Play 2.0</a> shipped and currently only provides the ability to create a self contained executable with bundled web server. Creating <span class="caps">WAR</span> files for more traditional application servers is on the roadmap but interestingly wasn&#8217;t deemed essential for the big 2.0 release. I had a nice chat with <a href="https://twitter.com/minglis">Martyn Inglis</a> at work about some of the nice side effects of this setup.</p>
<p>And throw in every time I have to configure straight Ruby applications for production environments I get cross. I know where all the bits and pieces are buried and can do it well, but with so many moving parts it&#8217;s absolutely no fun whatsoever.</p>
<p>Warbler, the JRuby tool for creating <span class="caps">WAR</span> files from Ruby source, has just added the ability to <a href="https://github.com/jruby/warbler/commit/0558a285eb59a0801cf7c0f274777b06b63883b3">embed Jetty to the master branch</a>.</p>
<p>I decided to take all of this for a quick spin, and the <a href="https://github.com/garethr/jruby-embedded-jetty">resulting code is up on GitHub</a>.</p>
<p>This is the simplest Rack application possible, it just prints <em>Hello Jetty</em>. And the <span class="caps">README</span> covers how to install and run it so I won&#8217;t duplcate that information here.</p>
<p>But I will print some nearly meaningless and unscientific benchmarks because, hey, who doesn&#8217;t like those?</p>
<pre>⚡ ab -c 50 -n 5000 http://localhost:8090/

Server Software:        Jetty(8.y.z-SNAPSHOT)
Server Hostname:        localhost
Server Port:            8090

Document Path:          /
Document Length:        16 bytes

Concurrency Level:      50
Time taken for tests:   1.827 seconds
Complete requests:      5000
Failed requests:        0
Write errors:           0
Total transferred:      555999 bytes
HTML transferred:       80144 bytes
Requests per second:    2736.47 [#/sec] (mean)
Time per request:       18.272 [ms] (mean)
Time per request:       0.365 [ms] (mean, across all concurrent requests)
Transfer rate:          297.16 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    2   2.2      1      18
Processing:     1   16   7.7     15      61
Waiting:        0   14   7.2     13      57
Total:          2   18   7.5     17      61

Percentage of the requests served within a certain time (ms)
  50%     17
  66%     19
  75%     21
  80%     22
  90%     27
  95%     30
  98%     42
  99%     52
 100%     61 (longest request)
</pre>
<p>Running the same test on the same machine but using Ruby 1.9.2-p290 and Thin gives.</p>
<pre>Server Software:        thin
Server Hostname:        localhost
Server Port:            9292

Document Path:          /
Document Length:        16 bytes

Concurrency Level:      50
Time taken for tests:   3.125 seconds
Complete requests:      5000
Failed requests:        0
Write errors:           0
Total transferred:      620620 bytes
HTML transferred:       80080 bytes
Requests per second:    1600.16 [#/sec] (mean)
Time per request:       31.247 [ms] (mean)
Time per request:       0.625 [ms] (mean, across all concurrent requests)
Transfer rate:          193.96 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.3      0       9
Processing:     3   31   6.4     33      52
Waiting:        3   25   6.4     28      47
Total:          4   31   6.4     33      52

Percentage of the requests served within a certain time (ms)
  50%     33
  66%     34
  75%     34
  80%     35
  90%     38
  95%     41
  98%     46
  99%     50
 100%     52 (longest request)</pre>
<p>2736 requests per second on JRuby/Jetty vs 1600 on Ruby/Thin. As noted this isn&#8217;t meaningfully useful, in that it&#8217;s a hello world example and I&#8217;ve not tried to pick the fastest stacks on either side. I&#8217;m more bothered about it not being slower, because the main reason to pursue this approach is simplicity. Having a single self contained artefact that contains all it&#8217;s dependencies including a production web server is very appealing.</p>
<p>I&#8217;m hoping to give this a go with some less trivial applications, and probably more importantly look to compare a production stack based around these self-contained executables vs the dependency chain that is modern Ruby application stacks.</p>
<p>Thanks to <a href="http://blog.nicksieger.com/">Nick Sieger</a> for both writing Warbler and for helping with a few questions on the JRuby mailing list and on Twitter. Thanks also to <a href="https://twitter.com/jabley">James Abley</a> for a few pointers on Java system properties.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Recent Projects And Talks]]></title>
    <link href="http://www.morethanseven.net/2012/03/31/Recent-projects-and-talks/"/>
    <updated>2012-03-31T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2012/03/31/Recent-projects-and-talks</id>
    <content type="html"><![CDATA[<p>I&#8217;ve been pretty busy with all things <a href="https://www.gov.uk"><span class="caps">GOV</span>.UK</a> recently but I&#8217;ve managed to get a few bits of unrelated code up and a few talks in. I&#8217;m <em>still</em> pretty busy so here&#8217;s a list of some of them rather than a proper blog post.</p>
<ul>
	<li><a href="http://www.slideshare.net/garethr/mining-puppet">Puppet Data Mining</a> talk from last weeks PuppetCamp in Edinburgh.</li>
	<li><a href="http://www.slideshare.net/garethr/web-operations">Introducting Web Operations</a> talk I gave at work to give my mainly non-development colleagues an idea about what it&#8217;s all about.</li>
	<li><a href="http://www.slideshare.net/garethr/learnings-from-govuk">Learning from building <span class="caps">GOV</span>.UK</a> talk I gave a month back or so to Cambridge Geek Night. We did an excellent full project retrospective after the beta launch and this lists some of the things we learnt.</li>
</ul>
<p>After someone bugged me on Twitter I realised the small bit of code we&#8217;ve been using for our Nagios dashboard wasn&#8217;t out in the wild. So introducing <a href="https://github.com/garethr/nash">Nash</a>, a very simple high level check dashboard which screenscrapes nagiosand runs happily on Heroku.</p>
<p>Although I&#8217;ve not been writing too much on here I&#8217;ve been keeping <a href="http://devopsweekly.com/">Devops Weekly</a> going each week for over a year now. I&#8217;ve just crossed 3000 subscribers which is pretty neat for a pet project.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dashboards At Gov.Uk]]></title>
    <link href="http://www.morethanseven.net/2012/02/19/Dashboards-at-govuk/"/>
    <updated>2012-02-19T00:00:00+00:00</updated>
    <id>http://www.morethanseven.net/2012/02/19/Dashboards-at-govuk</id>
    <content type="html"><![CDATA[<p>This is a bit of a cheat blog post really. I&#8217;ve been crazy busy all month with little time for anything except work (specifically shipping the first release of <a href="https://www.gov.uk/">www.gov.uk</a>). I have had a little time to blog over on the Cabinet Office blog though, about work we&#8217;ve done with dashboards.</p>
<p><a href="http://digital.cabinetoffice.gov.uk/2012/02/08/radiating-information/">http://digital.cabinetoffice.gov.uk/2012/02/08/radiating-information/</a></p>
<p>If you&#8217;re ever looking for good little hack projects dashboards are perfect, and often hugely useful once up and running. Convincing people of this before you have a few in the office might be hard &#8211; so just build something simple in a lunch break and find a screen to put it on. We&#8217;ve had great feedback from ours, both from people wandering through the office and from our colleagues who have a better idea of what&#8217;s going on.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Talking To Jenkins From Campfire With Hubot]]></title>
    <link href="http://www.morethanseven.net/2012/01/06/Talking-to-jenkins-from-campfire-with-hubot/"/>
    <updated>2012-01-06T00:00:00+00:00</updated>
    <id>http://www.morethanseven.net/2012/01/06/Talking-to-jenkins-from-campfire-with-hubot</id>
    <content type="html"><![CDATA[<p>In what turned out to be a productive holiday hacking with languages I&#8217;d not used before, I got round to writing some coffeescript on node.js. This was more to do with scratching a personal itch that pure experimentation. I had a play with <a href="https://github.com/github/janky">Janky</a> (Github&#8217;s Jenkins/Hubot mashup) but found it a little opinionated on the Jenkins side, but the campfire integration is excellent. Looking at the Jenkins commands in <a href="https://github.com/github/hubot-scripts/">hubot-scripts</a> though I found those even more opinionated.</p>
<p>The magic of open source though is you can just fix things, then ask nice people if they like what you&#8217;ve done. I set about writing a few more general commands and lo, the&#8217;ve been quickly <a href="https://github.com/github/hubot-scripts/pull/23840h">merged upstream</a>.</p>
<p>These add:</p>
<ul>
	<li>A command to list all your Jenkins jobs and the current state</li>
	<li>A command to trigger a normal build</li>
	<li>A command to trigger a build with a list of parameters</li>
</ul>
<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRipwAIM" alt="campfire window showing jenkins tasks"/></p>
<p>This was made much easier by first looking at the previous Jenkins commands, and then looking at other scripts in the hubot-scripts repository. The best way of learning a new language/framework is still on the shoulders of others.</p>
<p>I&#8217;ve got a few other good ideas for Jenkins related commands. I want to add a filter command to the jobs list, both by name and by current state. For longer running jobs I also want to report whether a build is currently running. And then maybe get information about a specific job, like the last few runs or similar. Any other requests or ideas most welcome.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[EC2 Tasks For Fabric]]></title>
    <link href="http://www.morethanseven.net/2011/12/31/Ec2-tasks-for-fabric/"/>
    <updated>2011-12-31T00:00:00+00:00</updated>
    <id>http://www.morethanseven.net/2011/12/31/Ec2-tasks-for-fabric</id>
    <content type="html"><![CDATA[<p>For running ad-hoc commands across a small number of servers you really can&#8217;t beat <a href="http://fabfile.org">Fabric</a>. It requires nothing other than ssh installed on the servers, is generally just a one-line install and requires next to no syntaxtic fluff between you and the commands you want running. It&#8217;s much more of a swiss army knife to Capistranos bread knife.</p>
<p>I&#8217;ve found myself doing more and more EC2 work of late and have finally gotten around to making my life easier when using Fabric with Amazon instances. The result of a bit of hacking is <a href="https://github.com/garethr/cloth">Cloth</a> (also <a href="http://pypi.python.org/pypi/cloth">available on PyPi</a>). It contains some utility functions and a few handy tasks for loading host details from the EC2 <span class="caps">API</span> and using them in your Fabric tasks. No more static lists of host names that constantly need updating in your fabfile.</p>
<p>Specifically, with a fabfile that looks like:</p>
<pre>#! /usr/bin/env python
from cloth.tasks import *</pre>
<p>You can run:</p>
<pre>fab all list</pre>
<p>And get something like:</p>
<pre>instance-name-1 (xx.xxx.xxx.xx, xxx.xx.xx.xx)
instance-name-2 (xx.xxx.xxx.xx, xxx.xx.xx.xx)
instance-name-3 (xx.xxx.xxx.xx, xxx.xx.xx.xx)
instance-name-4 (xx.xxx.xxx.xx, xxx.xx.xx.xx)
instance-name-5 (xx.xxx.xxx.xx, xxx.xx.xx.xx)
instance-name-6 (xx.xxx.xxx.xx, xxx.xx.xx.xx)
instance-name-7 (xx.xxx.xxx.xx, xxx.xx.xx.xx)
instance-name-8 (xx.xxx.xxx.xx, xxx.xx.xx.xx)
...</pre>
<p>And then you could run:</p>
<pre>fab -P all uptime</pre>
<p>And you&#8217;d happily get the load averages and uptime for all your EC2 instances.</p>
<p>A few more tricks are documented in the <a href="https://github.com/garethr/cloth">GitHub <span class="caps">README</span></a>, including filtering the list by a regex and some convention based mapping to Fabric roles. I&#8217;ll hopefully add a few more features as I need them and generally tidy up a few things but I&#8217;m pretty happy with it so far.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[First Experience Building Something With Clojure]]></title>
    <link href="http://www.morethanseven.net/2011/12/26/First-experience-building-something-with-clojure/"/>
    <updated>2011-12-26T00:00:00+00:00</updated>
    <id>http://www.morethanseven.net/2011/12/26/First-experience-building-something-with-clojure</id>
    <content type="html"><![CDATA[<p>I nearly always try and grab some time over Christmas to try something new and this year I&#8217;d been planning on spending some time with Clojure. I have several friends who are big fans, but dipping in and out of a book hadn&#8217;t really worked. What I needed was an itch to scratch.</p>
<p>I stuck with a domain I&#8217;m pretty familiar with for this first project, namely building a little web application. It renders a web page, makes <span class="caps">HTTP</span> requests, parses <span class="caps">JSON</span> into native data structures and does a bit of data juggling. Nothing fancy or overly ambitious, I was mainly interested in picking up the syntax, understanding common libraries and getting something built. Here&#8217;s what I&#8217;ve got:</p>
<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRjBuAIM" alt="Dasboard for Jenkins builds"/></p>
<p>Jenkins has various <span class="caps">API</span> endpoints, but most dashboards I&#8217;ve seen concentrate on showing you the current status of all the builds. This is hugely useful when it comes to the simple case of continuous integration, but I&#8217;ve also been using Jenkins for other automation tasks, and making extensive use of parameterized builds. What the dashboard above concentrates on is showing recent builds for a specific job, along with the parameters used to run them.</p>
<p>Overall it was a fun project. Clojure made much more sense to me building this application than it had from simple examples. The <a href="http://webnoir.org/">Noir</a> web framework is excellent and proved easy enough to jump into and simple enough that I could read the source code if I was interested in how something worked. The <a href="https://github.com/technomancy/leiningen">Leiningen</a> build tool made getting started, downloading and managing dependencies and running tests and the application itself easy.</p>
<p>What I didn&#8217;t find particularly appealing was the lack of a strong standard library coupled with the difficulty of tracking down suitable libraries. <span class="caps">JSON</span> parsing, dealing with <span class="caps">HTTP</span> requests and date handing are very common activities in web programming and all needed me to jump around looking at the best way of dealing with the common case. I settled on <a href="https://github.com/dakrone/clj-http">clj-http</a>, <a href="https://github.com/dakrone/cheshire">chesire</a> and using Java interop for date formatting. clj-http suffered from having lots of forks on GitHub to navigate through. I started with clojure-json before discovering it had been deprecated. And neither clj-time or date-clj appeared to support unix timestamps as far as I could tell from the source. Throw in some uncertainty over the status of clojure-contrib that isn&#8217;t well documented on the official site and it needs some effort to get started.</p>
<p>The working code for this is already up on <a href="https://github.com/garethr/jenkins-build-list">GitHub</a> and I&#8217;d be interested in any Clojure experts showing me the error of my ways.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Setting Puppet Class Using Environment Variables]]></title>
    <link href="http://www.morethanseven.net/2011/12/13/Setting-puppet-class-using-environment-variables/"/>
    <updated>2011-12-13T00:00:00+00:00</updated>
    <id>http://www.morethanseven.net/2011/12/13/Setting-puppet-class-using-environment-variables</id>
    <content type="html"><![CDATA[<p>I&#8217;m not sure how novel this approach is but a few folks at work hadn&#8217;t seen it before so I thought it worth jotting down.</p>
<p>If you have even a small but dynamic set of servers then a problem arises with how those nodes are defined in puppet. A node remember is defined in puppet like so:</p>
<pre>node web3.example.com {
  include web_server
}</pre>
<p>The problem is twofold. If you have a growing infrastructure, that list of nodes is going to get quickly out of hand. The other problem is around provisioning new hosts, the obvious approach to which is something like:</p>
<p>1. Summon new EC2 instance<br />
2. Change the node definition to include the new hostname<br />
3. Install puppet on instance and so the ssl certificate signing dance<br />
4. Run puppet</p>
<p>Step 2 stands out. The others are easily automated, but do you want to automate a change to your puppet manifests and a redeploy to the puppetmaster for a new instance? Probably not.<br />
Puppet has the concept of an external node classifier which can be used to solve this problem, but another simpler approach is to use an environment variable on the new machine.</p>
<p>Lets say we define our nodes something like this instead:</p>
<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>node default {
</span><span class='line'>  case $machine_role {
</span><span class='line'>    frontend:           { include web_server }
</span><span class='line'>    backend:            { include app_server }
</span><span class='line'>    data:               { include db_server }
</span><span class='line'>    monitoring:         { include monitoring_server }
</span><span class='line'>    development:        { include development }
</span><span class='line'>    default:            { include base }
</span><span class='line'>  }
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure></div></notextile></p>
<p>If a machine runs and sets the $machine_role variable to frontend it includes the web_server class, if that variable equals &#8216;data&#8217; it&#8217;s going to include the db_server class instead. Much cleaner and more maintainable in my view. Now to set that variable.</p>
<p>Facter is the tool used by Puppet to get system information like the operating system or processor count. You can use these facter provided variables anywhere in your manifests. And one way of adding a new fact is via an environment variable on the client. Any environment variable prefixed with FACTER_ will be available in Puppet manifests. So in this case we can:</p>
<pre>export FACTER_machine_role=frontend</pre>
<p>So our steps from above become something like:</p>
<p>1. Summon new machine<br />
2. echo &#8220;export FACTER_machine_role=backend&#8221; &gt;&gt; /etc/environment<br />
3. Install puppet on instance and so the ssl certificate signing dance<br />
4. Run puppet</p>
<p>Much easier to automate. And if you&#8217;re looking at a box and want to know what it&#8217;s role is you can check the relevant environment variable.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Jenkins Parameterized Builds]]></title>
    <link href="http://www.morethanseven.net/2011/11/16/Jenkins-parameterized-builds/"/>
    <updated>2011-11-16T00:00:00+00:00</updated>
    <id>http://www.morethanseven.net/2011/11/16/Jenkins-parameterized-builds</id>
    <content type="html"><![CDATA[<p>I&#8217;m a huge Jenkins fan now, but that wasn&#8217;t always the case. I started (and still have a soft spot for) Cruise Control, mainly building .<span class="caps">NET</span> and <span class="caps">PHP</span> applications. I then jumped to much simpler projects like <a href="http://integrityapp.com/">Integrity</a> mainly for Python and Ruby projects. I reasoned I didn&#8217;t need the complexity of Cruise or Hudson, I just wanted to be able to run my tests on a remote machine and have something go green or red. I then worked out that wasn&#8217;t quite the case, and ended up committing webhook like functionality to Integrity so I could chain builds together. And then I eventually tried Jenkins and found it&#8217;s power mixed with flexibility won me over. That&#8217;s really all just context, but hopefully explains a little about why I like a few Jenkins features in particular, one of which is <a href="https://wiki.jenkins-ci.org/display/JENKINS/Parameterized+Build">Parameterized builds</a>.</p>
<p>The Jenkins wiki describes this by saying:</p>
<blockquote>
<p>Sometimes, it is useful/necessary to have your builds take several &#8220;parameters.&#8221;</p>
</blockquote>
<p>But then goes onto a usecase that probably won&#8217;t mean much to dynamic language folk. This is one failing of much of the documentation around Jenkins, it often feels geared towards developers of certain languages when in reality the tool is useful everywhere. The important take away here is that builds can take arguments, which can have default values. Here&#8217;s an example:</p>
<p>Imagine we have a build which runs a set of simple tests against a live system . And further imagine that said system is composed of a number of different web services. Oh, and we&#8217;re running a few different parrallel versions of the entire system for testing and staging purposes. We could have one Jenkins job per application/environment combination. Or we could have one parameterized build.</p>
<p>Lets first specify our parameters from the Configure build screen of our Job.</p>
<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRjZsAIM"/></p>
<p>Here we&#8217;re specifying a TARGET_APPLICATION and TARGET_PLATFORM parameter. These are going to turn into environment variables we can use in our build steps. We can specify default values for these if we like too. I&#8217;m just using strings here, but I could also use a select box or file dialog, or other options provided by various plugins.</p>
<p>Now when we hit the build button, instead of the build just starting, we&#8217;re propted for these values.</p>
<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRjxqAIM"/></p>
<p>So with our new build if we want it to run against the staging environment and just for the foobar application we enter those values and hit build. That on it&#8217;s own can be used to drastically cut down on the number of individual builds you have to manage in Jenkins. And we&#8217;re not just restricted to text inputs, we can use boolean values or even prompt for file uploads at build time. But throw in a few plugins and things get even more interesting.</p>
<p>Jenkins has an overwhelming number of plugin available. If you haven&#8217;t spent the good half hour it takes to go down the list I&#8217;d highly recommend it. One of Jenkins best features is the ability to trigger a build after the successful run of another job. It allows you to chain things like test runs to integration deployments to smoke tests to production deploys. Basically your modern continuous deployment/delivery pipeline. The <a href="https://wiki.jenkins-ci.org/display/JENKINS/Build+Pipeline+Plugin">Build Pipeline</a> plugin is excellent for visuallising this and introducing human gates if needed. Another useful plugin in this context is the <a href="https://wiki.jenkins-ci.org/display/JENKINS/Parameterized+Trigger+Plugin">Parameterized Trigger</a> plugin. A limitation of Jenkins is that downstream builds can&#8217;t pass parameters, but this plugin works around that. Instead of ticking the <em>Build other projects</em> option you go for the <em>Trigger parameterized build on other projects</em> box. This allows you to select the project and to specify parameters to pass. This could be hard coded values, paramaters already passed into the pipeline, or things from other plugins like the git sha1 hash or subversion version number.</p>
<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRjyqAIM"/></p>
<p>Combine all this together and it&#8217;s simple to have a per project continuous integration build running a test suite, kicking off a standard set of downsteam jobs for deploying to a test environment (by passing th relevant parameters), running some basic smoke tests and allowing someone to click a button to deploy to production. Or going the whole continuous deployment, I trust my test suite route, and deploying automatically. All within Jenkins. Getting this working requires a bit of planning. You want all of your projects to be deployed the same way but you probably want this to be the case anyway.</p>
<p>Providing flexible push button builds/deploys and reducing the number of nearly identical jobs in Jenkins are just two advantages to using parameterized builds. Most of the tricks come from thinking about Jenkins as much more than a continuous integration tool and more of an automation framework &#8211; I know at least one large organisation who have pretty much replaced cron for many tasks with Jenkins for instance. Running tests automatically, and in a central environment as close to production as possible, is important. But it&#8217;s just a sanity check if you&#8217;re doing everything right already. Centralising activity on a build pipeline requires you to be doing all that anyway, but in my opinion gives way more useful and rapid feedback about the state of the code your team is writing.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Exposing Puppet And Facter Information On The Web]]></title>
    <link href="http://www.morethanseven.net/2011/11/02/Exposing-puppet-and-facter-information-on-the-web/"/>
    <updated>2011-11-02T00:00:00+00:00</updated>
    <id>http://www.morethanseven.net/2011/11/02/Exposing-puppet-and-facter-information-on-the-web</id>
    <content type="html"><![CDATA[<p>I don&#8217;t appear to have been in a writing mood recently but I&#8217;ve been getting back into hacking on a couple of pet projects. The first fruits of this coding (mainly backwards and forwards on the train) I&#8217;ve just made available to anyone interested.</p>
<p><a href="https://github.com/garethr/web-puppet">Web Facter</a> is a gem which takes the output from <a href="https://github.com/puppetlabs/facter">Facter</a> and exposes this as <span class="caps">JSON</span> over <span class="caps">HTTP</span>. In theory you could run this on a configurable port on each of your machines and have a <span class="caps">URL</span> you can hit to get information on uptime, networking setup, hostnames or anything else exposed by Facter. It comes with a simple built-in web server and optional http basic authentication if you&#8217;re not going to do this via a proxy. The <span class="caps">JSON</span> display should be both human and machine readable, and I have a few ideas for projects which needed this information.</p>
<p>The other project is very similar, and even has a similar name, <a href="https://github.com/garethr/web-facter">Web Puppet</a>. You can run this on your puppet master and it exposes the node information (currently including the facts and tags) again as <span class="caps">JSON</span> over <span class="caps">HTTP</span>. I&#8217;m still working on this to make it a little more usable. At the moment it just shows you all nodes and all information, if you&#8217;re working with a larger cluster this isn&#8217;t really sensible. Recent versions of Puppet do have an <a href="http://docs.puppetlabs.com/guides/rest_api.html"><span class="caps">HTTP</span> based <span class="caps">API</span></a> but it requires some hoops to be jumped through and I&#8217;m not quite sure from the docs it lets me do what I want (I have a specific usecase, of which more soon all being well).</p>
<p>Both projects have had me reading the source code of Puppet and Facter, which for the most part has been enjoyable and informative. Puppet in particular has some great comments lying around :) Both of the above projects are available as gems for anyone else to play around with and build on, but my main aim is a little more high level. All being well I&#8217;ll have a couple of projects built atop these APIs shortly.</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Javascript In Your Ruby: Mongoid Map Reduce]]></title>
    <link href="http://www.morethanseven.net/2011/10/10/Javascript-in-your-ruby-mongoid-map-reduce/"/>
    <updated>2011-10-10T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2011/10/10/Javascript-in-your-ruby-mongoid-map-reduce</id>
    <content type="html"><![CDATA[<p>We&#8217;re pretty fond of <a href="http://mongodb.org/">Mongodb</a> at work and I&#8217;ve been getting an opportunity to kick some of the more interesting tyres recently. I thought I&#8217;d document something I found myself doing here, half hoping it might be useful for anyone else with a similar problem and also to see if anyone else has a much neater approach. The examples are obviously pretty trivial, but hopefully you get the idea.</p>
<p>So, we&#8217;re making using of the rather nice <a href="http://mongoid.org/">Mongoid</a> Ruby library for defining our models as Ruby classes. Here&#8217;s a couple of very simple classes. Anyone familiar with DataMapper or Django&#8217;s <span class="caps">ORM</span> should be right at home here.</p>
<pre>class Publication
  include Mongoid::Document

  field :name,            :type =&gt; String
  field :section,         :type =&gt; String
  field :body,            :type =&gt; String
  field :is_published,    :type =&gt; Boolean
end

class LongerPublication &lt; Publication
  field :extra_body,      :type =&gt; String
end
</pre>
<p>So we now have a good few publications and longer publications in our system. And folks have been creating sections with wild amandon. What I&#8217;d like to do now is do some reporting, specifically I want to know the numbers of Publications by type and publication status. And lets allow a breakdown by section while we&#8217;re at it.</p>
<p>One approach to this is using Mongo&#8217;s built in map-reduce capability. Mongoid exposes this pretty cleanly in my view, by allowing you to write the required javascript functions (a mapper and a reducer) inline in the Ruby code. This might feel evil, but seems the best of the available options. I can see for much larger functions that splitting this out into separate javascript files for ease of testing might be nice, but were you can just test the input/output of the whole job this works for me.</p>
<pre>KLASS = "this._type"
SECTION = "this.section"

def self.count_by(type)
  map = &lt;&lt;EOF
    function() {
      function truthy(value) {
        return (value == true) ? 1 : 0;
      }
      emit(#{type}, {type: #{type}, count: 1, published: truthy(this.is_published)})
    }
EOF

  reduce = &lt;&lt;EOF
    function(key, values) {
      var count = 0; published = 0;
      values.forEach(function(doc) {
        count += parseInt(doc.count);
        published += parseInt(doc.published);
        type = doc.type
      );
      return {type: type, count: count, published: published}
    }
EOF

  collection.mapreduce(map, reduce).find()

end
</pre>
<p>In our case that will return something like the following, or rather more specifically it will return a Mongo::Cursor that allows you to get at the following data.</p>
<pre>[{"_id"=&gt;"Publication", "value"=&gt;{"type"=&gt;"Publication", "count"=&gt;42.0, "published"=&gt;29.0}},
{"_id"=&gt;"LongerPublication", "value"=&gt;{"type"=&gt;"LongerPublication", "count"=&gt;12.0, "published"=&gt;10.0}}]
</pre>
<p>I&#8217;ve been pretty impressed with both Mongo and Mongoid here. I like the feel of mapreduce jobs for this sort of reporting task. In particular it&#8217;s suprising how writing two languages mixed together like this doesn&#8217;t really affect the readability of the code in my view. Given that with a relational database you&#8217;d probably be writing <span class="caps">SQL</span> anyway maybe that&#8217;s not that suprising &#8211; the syntactic differences between Javascript and Ruby are much smaller than pretty much anything and <span class="caps">SQL</span>. Lots of folks have written about the increase of polyglot programming, but I wonder if we&#8217;ll see an increase in the embedding of one language in another?</p>]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rundeck And Nagios Nrpe Checks]]></title>
    <link href="http://www.morethanseven.net/2011/09/11/Rundeck-and-nagios-nrpe-checks/"/>
    <updated>2011-09-11T00:00:00+01:00</updated>
    <id>http://www.morethanseven.net/2011/09/11/Rundeck-and-nagios-nrpe-checks</id>
    <content type="html"><![CDATA[<p>I&#8217;ve been playing with <a href="http://rundeck.org/">Rundeck</a> recently. For those that haven&#8217;t seen it yet it&#8217;s an application for running commands across a cluster of machines and recording the results. It has both a command line client and a very rich web interface which boths allows you to trigger commands and shows the results.</p>
<p>I&#8217;ve played with a few different jobs so far, including triggering Puppet runs across machines triggered by a Jenkins plugin. I&#8217;ve also been looking at running all my monitoring tasks at the click of a button (or again as part of a smoke test triggered by Jenkins) and I thought that might make a nice simple example.</p>
<p>My checks are written as Nagios plugins, and run periodically by Nagios. I also trigger them manually, using Dean&#8217;s <a href="http://www.unixdaemon.net/tools/commandline/introducing-nrpe-runner.html"><span class="caps">NRPE</span> runner script</a>.</p>
<p><img src="http://image-host.appspot.com/i/img?id=agppbWFnZS1ob3N0cg0LEgVJbWFnZRiJoQIM" alt="Rundeck showing a job output"/></p>
<p>The above shows a successful run across a few machines I use for experimenting with tools. Hopefully you can see the summary of the run on each of the four machines, each ran five <span class="caps">NRPE</span> checks and all passed. On failure we&#8217;d see the results as well as different symbols and colous. We can easily save the output to a file if we need to, rerun or duplicate the job (maybe to have it run against a different group of machines) or we can export the job definition file to load into another instance.</p>
<p>The same job can also be run on the command line (which makes use the of Rundeck <span class="caps">API</span>)</p>
<pre>./run -j "Run NRPE checks" -p PRGMR</pre>
<p>This example shows running a specific pre-defined job, but it&#8217;s also equally possible to fire of adhoc commands to some or all of the machines rundeck knows about.</p>
<p>One thing in particular that I prefer about this approach to say using Capistrano or Fabric for remote execution tasks is that you have a centralised authentication and logging capability. It would be easy enough to encapsulate the jobs into cap or fabric tasks (and manage that in source control) which means you&#8217;re not stuck if Rundeck isn&#8217;t available.</p>]]></content>
  </entry>
  
</feed>
